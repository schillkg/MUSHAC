{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat,savemat\n",
    "import nibabel as nib\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "\n",
    "bs_size = 1000\n",
    "\n",
    "# bigger patch 5by5\n",
    "# dropout layers\n",
    "# adding channel of anatomical label for input\n",
    "# do both SH1200 and SH3000 together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['A','B','C','D','E','F','G','I','J','K']\n",
    "\n",
    "X = np.empty((5,5,5,31,0))\n",
    "Y = np.empty((1,1,1,30,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kurtschilling/Data/harmonization/patches/sA_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sA_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 79983)\n",
      "(5, 5, 5, 1, 79983)\n",
      "(1, 1, 1, 15, 79983)\n",
      "(1, 5, 5, 15, 79983)\n",
      "(5, 5, 5, 1, 79983)\n",
      "(1, 1, 1, 15, 79983)\n",
      "(5, 5, 5, 31, 79983)\n",
      "(1, 1, 1, 30, 79983)\n",
      "(79983,)\n",
      "(5, 5, 5, 31, 79983)\n",
      "(1, 1, 1, 30, 79983)\n",
      "(79983,)\n",
      "(5, 5, 5, 31, 79972)\n",
      "(1, 1, 1, 30, 79972)\n",
      "(79972,)\n",
      "(5, 5, 5, 31, 79972)\n",
      "(1, 1, 1, 30, 79972)\n",
      "(79972,)\n",
      "(5, 5, 5, 31, 79959)\n",
      "(1, 1, 1, 30, 79959)\n",
      "79959.0\n",
      "39980.0\n",
      "float64\n",
      "float64\n",
      "(39980,)\n",
      "(79959,)\n",
      "[ True  True False ... False False  True]\n",
      "(5, 5, 5, 31, 79959)\n",
      "(1, 1, 1, 30, 79959)\n",
      "79959.0\n",
      "39980.0\n",
      "float64\n",
      "float64\n",
      "(39980,)\n",
      "(79959,)\n",
      "[ True  True False ... False False  True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:73: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:73: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 5, 31, 39979)\n",
      "(1, 1, 1, 30, 39979)\n",
      "(5, 5, 5, 31, 39979)\n",
      "(1, 1, 1, 30, 39979)\n",
      "/Users/kurtschilling/Data/harmonization/patches/sB_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sB_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 91254)\n",
      "(5, 5, 5, 1, 91254)\n",
      "(1, 1, 1, 15, 91254)\n",
      "(1, 5, 5, 15, 91254)\n",
      "(5, 5, 5, 1, 91254)\n",
      "(1, 1, 1, 15, 91254)\n",
      "(5, 5, 5, 31, 91254)\n",
      "(1, 1, 1, 30, 91254)\n",
      "(91254,)\n",
      "(5, 5, 5, 31, 91254)\n",
      "(1, 1, 1, 30, 91254)\n",
      "(91254,)\n",
      "(5, 5, 5, 31, 91240)\n",
      "(1, 1, 1, 30, 91240)\n",
      "(91240,)\n",
      "(5, 5, 5, 31, 91240)\n",
      "(1, 1, 1, 30, 91240)\n",
      "(91240,)\n",
      "(5, 5, 5, 31, 91233)\n",
      "(1, 1, 1, 30, 91233)\n",
      "91233.0\n",
      "45616.0\n",
      "float64\n",
      "float64\n",
      "(45616,)\n",
      "(91233,)\n",
      "[False False False ... False  True  True]\n",
      "(5, 5, 5, 31, 91233)\n",
      "(1, 1, 1, 30, 91233)\n",
      "91233.0\n",
      "45616.0\n",
      "float64\n",
      "float64\n",
      "(45616,)\n",
      "(91233,)\n",
      "[False False False ... False  True  True]\n",
      "(5, 5, 5, 31, 45617)\n",
      "(1, 1, 1, 30, 45617)\n",
      "(5, 5, 5, 31, 45617)\n",
      "(1, 1, 1, 30, 45617)\n",
      "/Users/kurtschilling/Data/harmonization/patches/sC_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sC_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 84951)\n",
      "(5, 5, 5, 1, 84951)\n",
      "(1, 1, 1, 15, 84951)\n",
      "(1, 5, 5, 15, 84951)\n",
      "(5, 5, 5, 1, 84951)\n",
      "(1, 1, 1, 15, 84951)\n",
      "(5, 5, 5, 31, 84951)\n",
      "(1, 1, 1, 30, 84951)\n",
      "(84951,)\n",
      "(5, 5, 5, 31, 84951)\n",
      "(1, 1, 1, 30, 84951)\n",
      "(84951,)\n",
      "(5, 5, 5, 31, 84909)\n",
      "(1, 1, 1, 30, 84909)\n",
      "(84909,)\n",
      "(5, 5, 5, 31, 84909)\n",
      "(1, 1, 1, 30, 84909)\n",
      "(84909,)\n",
      "(5, 5, 5, 31, 84890)\n",
      "(1, 1, 1, 30, 84890)\n",
      "84890.0\n",
      "42445.0\n",
      "float64\n",
      "float64\n",
      "(42445,)\n",
      "(84890,)\n",
      "[False  True  True ... False False  True]\n",
      "(5, 5, 5, 31, 84890)\n",
      "(1, 1, 1, 30, 84890)\n",
      "84890.0\n",
      "42445.0\n",
      "float64\n",
      "float64\n",
      "(42445,)\n",
      "(84890,)\n",
      "[False  True  True ... False False  True]\n",
      "(5, 5, 5, 31, 42445)\n",
      "(1, 1, 1, 30, 42445)\n",
      "(5, 5, 5, 31, 42445)\n",
      "(1, 1, 1, 30, 42445)\n",
      "/Users/kurtschilling/Data/harmonization/patches/sD_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sD_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 80276)\n",
      "(5, 5, 5, 1, 80276)\n",
      "(1, 1, 1, 15, 80276)\n",
      "(1, 5, 5, 15, 80276)\n",
      "(5, 5, 5, 1, 80276)\n",
      "(1, 1, 1, 15, 80276)\n",
      "(5, 5, 5, 31, 80276)\n",
      "(1, 1, 1, 30, 80276)\n",
      "(80276,)\n",
      "(5, 5, 5, 31, 80276)\n",
      "(1, 1, 1, 30, 80276)\n",
      "(80276,)\n",
      "(5, 5, 5, 31, 80274)\n",
      "(1, 1, 1, 30, 80274)\n",
      "(80274,)\n",
      "(5, 5, 5, 31, 80274)\n",
      "(1, 1, 1, 30, 80274)\n",
      "(80274,)\n",
      "(5, 5, 5, 31, 80273)\n",
      "(1, 1, 1, 30, 80273)\n",
      "80273.0\n",
      "40136.0\n",
      "float64\n",
      "float64\n",
      "(40136,)\n",
      "(80273,)\n",
      "[ True False  True ... False False False]\n",
      "(5, 5, 5, 31, 80273)\n",
      "(1, 1, 1, 30, 80273)\n",
      "80273.0\n",
      "40136.0\n",
      "float64\n",
      "float64\n",
      "(40136,)\n",
      "(80273,)\n",
      "[ True False  True ... False False False]\n",
      "(5, 5, 5, 31, 40137)\n",
      "(1, 1, 1, 30, 40137)\n",
      "(5, 5, 5, 31, 40137)\n",
      "(1, 1, 1, 30, 40137)\n",
      "/Users/kurtschilling/Data/harmonization/patches/sE_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sE_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 82775)\n",
      "(5, 5, 5, 1, 82775)\n",
      "(1, 1, 1, 15, 82775)\n",
      "(1, 5, 5, 15, 82775)\n",
      "(5, 5, 5, 1, 82775)\n",
      "(1, 1, 1, 15, 82775)\n",
      "(5, 5, 5, 31, 82775)\n",
      "(1, 1, 1, 30, 82775)\n",
      "(82775,)\n",
      "(5, 5, 5, 31, 82775)\n",
      "(1, 1, 1, 30, 82775)\n",
      "(82775,)\n",
      "(5, 5, 5, 31, 82735)\n",
      "(1, 1, 1, 30, 82735)\n",
      "(82735,)\n",
      "(5, 5, 5, 31, 82735)\n",
      "(1, 1, 1, 30, 82735)\n",
      "(82735,)\n",
      "(5, 5, 5, 31, 82726)\n",
      "(1, 1, 1, 30, 82726)\n",
      "82726.0\n",
      "41363.0\n",
      "float64\n",
      "float64\n",
      "(41363,)\n",
      "(82726,)\n",
      "[False  True False ...  True  True False]\n",
      "(5, 5, 5, 31, 82726)\n",
      "(1, 1, 1, 30, 82726)\n",
      "82726.0\n",
      "41363.0\n",
      "float64\n",
      "float64\n",
      "(41363,)\n",
      "(82726,)\n",
      "[False  True False ...  True  True False]\n",
      "(5, 5, 5, 31, 41363)\n",
      "(1, 1, 1, 30, 41363)\n",
      "(5, 5, 5, 31, 41363)\n",
      "(1, 1, 1, 30, 41363)\n",
      "/Users/kurtschilling/Data/harmonization/patches/sF_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sF_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 84027)\n",
      "(5, 5, 5, 1, 84027)\n",
      "(1, 1, 1, 15, 84027)\n",
      "(1, 5, 5, 15, 84027)\n",
      "(5, 5, 5, 1, 84027)\n",
      "(1, 1, 1, 15, 84027)\n",
      "(5, 5, 5, 31, 84027)\n",
      "(1, 1, 1, 30, 84027)\n",
      "(84027,)\n",
      "(5, 5, 5, 31, 84027)\n",
      "(1, 1, 1, 30, 84027)\n",
      "(84027,)\n",
      "(5, 5, 5, 31, 83989)\n",
      "(1, 1, 1, 30, 83989)\n",
      "(83989,)\n",
      "(5, 5, 5, 31, 83989)\n",
      "(1, 1, 1, 30, 83989)\n",
      "(83989,)\n",
      "(5, 5, 5, 31, 83965)\n",
      "(1, 1, 1, 30, 83965)\n",
      "83965.0\n",
      "41982.0\n",
      "float64\n",
      "float64\n",
      "(41982,)\n",
      "(83965,)\n",
      "[False  True  True ...  True False False]\n",
      "(5, 5, 5, 31, 83965)\n",
      "(1, 1, 1, 30, 83965)\n",
      "83965.0\n",
      "41982.0\n",
      "float64\n",
      "float64\n",
      "(41982,)\n",
      "(83965,)\n",
      "[False  True  True ...  True False False]\n",
      "(5, 5, 5, 31, 41983)\n",
      "(1, 1, 1, 30, 41983)\n",
      "(5, 5, 5, 31, 41983)\n",
      "(1, 1, 1, 30, 41983)\n",
      "/Users/kurtschilling/Data/harmonization/patches/sG_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sG_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 95564)\n",
      "(5, 5, 5, 1, 95564)\n",
      "(1, 1, 1, 15, 95564)\n",
      "(1, 5, 5, 15, 95564)\n",
      "(5, 5, 5, 1, 95564)\n",
      "(1, 1, 1, 15, 95564)\n",
      "(5, 5, 5, 31, 95564)\n",
      "(1, 1, 1, 30, 95564)\n",
      "(95564,)\n",
      "(5, 5, 5, 31, 95564)\n",
      "(1, 1, 1, 30, 95564)\n",
      "(95564,)\n",
      "(5, 5, 5, 31, 95557)\n",
      "(1, 1, 1, 30, 95557)\n",
      "(95557,)\n",
      "(5, 5, 5, 31, 95557)\n",
      "(1, 1, 1, 30, 95557)\n",
      "(95557,)\n",
      "(5, 5, 5, 31, 95546)\n",
      "(1, 1, 1, 30, 95546)\n",
      "95546.0\n",
      "47773.0\n",
      "float64\n",
      "float64\n",
      "(47773,)\n",
      "(95546,)\n",
      "[False  True  True ... False  True  True]\n",
      "(5, 5, 5, 31, 95546)\n",
      "(1, 1, 1, 30, 95546)\n",
      "95546.0\n",
      "47773.0\n",
      "float64\n",
      "float64\n",
      "(47773,)\n",
      "(95546,)\n",
      "[False  True  True ... False  True  True]\n",
      "(5, 5, 5, 31, 47773)\n",
      "(1, 1, 1, 30, 47773)\n",
      "(5, 5, 5, 31, 47773)\n",
      "(1, 1, 1, 30, 47773)\n",
      "/Users/kurtschilling/Data/harmonization/patches/sI_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sI_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 86948)\n",
      "(5, 5, 5, 1, 86948)\n",
      "(1, 1, 1, 15, 86948)\n",
      "(1, 5, 5, 15, 86948)\n",
      "(5, 5, 5, 1, 86948)\n",
      "(1, 1, 1, 15, 86948)\n",
      "(5, 5, 5, 31, 86948)\n",
      "(1, 1, 1, 30, 86948)\n",
      "(86948,)\n",
      "(5, 5, 5, 31, 86948)\n",
      "(1, 1, 1, 30, 86948)\n",
      "(86948,)\n",
      "(5, 5, 5, 31, 86921)\n",
      "(1, 1, 1, 30, 86921)\n",
      "(86921,)\n",
      "(5, 5, 5, 31, 86921)\n",
      "(1, 1, 1, 30, 86921)\n",
      "(86921,)\n",
      "(5, 5, 5, 31, 86906)\n",
      "(1, 1, 1, 30, 86906)\n",
      "86906.0\n",
      "43453.0\n",
      "float64\n",
      "float64\n",
      "(43453,)\n",
      "(86906,)\n",
      "[False False  True ... False  True False]\n",
      "(5, 5, 5, 31, 86906)\n",
      "(1, 1, 1, 30, 86906)\n",
      "86906.0\n",
      "43453.0\n",
      "float64\n",
      "float64\n",
      "(43453,)\n",
      "(86906,)\n",
      "[False False  True ... False  True False]\n",
      "(5, 5, 5, 31, 43453)\n",
      "(1, 1, 1, 30, 43453)\n",
      "(5, 5, 5, 31, 43453)\n",
      "(1, 1, 1, 30, 43453)\n",
      "/Users/kurtschilling/Data/harmonization/patches/sJ_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sJ_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 90433)\n",
      "(5, 5, 5, 1, 90433)\n",
      "(1, 1, 1, 15, 90433)\n",
      "(1, 5, 5, 15, 90433)\n",
      "(5, 5, 5, 1, 90433)\n",
      "(1, 1, 1, 15, 90433)\n",
      "(5, 5, 5, 31, 90433)\n",
      "(1, 1, 1, 30, 90433)\n",
      "(90433,)\n",
      "(5, 5, 5, 31, 90433)\n",
      "(1, 1, 1, 30, 90433)\n",
      "(90433,)\n",
      "(5, 5, 5, 31, 90427)\n",
      "(1, 1, 1, 30, 90427)\n",
      "(90427,)\n",
      "(5, 5, 5, 31, 90427)\n",
      "(1, 1, 1, 30, 90427)\n",
      "(90427,)\n",
      "(5, 5, 5, 31, 90422)\n",
      "(1, 1, 1, 30, 90422)\n",
      "90422.0\n",
      "45211.0\n",
      "float64\n",
      "float64\n",
      "(45211,)\n",
      "(90422,)\n",
      "[False  True  True ...  True  True False]\n",
      "(5, 5, 5, 31, 90422)\n",
      "(1, 1, 1, 30, 90422)\n",
      "90422.0\n",
      "45211.0\n",
      "float64\n",
      "float64\n",
      "(45211,)\n",
      "(90422,)\n",
      "[False  True  True ...  True  True False]\n",
      "(5, 5, 5, 31, 45211)\n",
      "(1, 1, 1, 30, 45211)\n",
      "(5, 5, 5, 31, 45211)\n",
      "(1, 1, 1, 30, 45211)\n",
      "/Users/kurtschilling/Data/harmonization/patches/sK_A2B_5Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/patches/sK_A2B_5Patches.mat\n",
      "(1, 5, 5, 15, 87522)\n",
      "(5, 5, 5, 1, 87522)\n",
      "(1, 1, 1, 15, 87522)\n",
      "(1, 5, 5, 15, 87522)\n",
      "(5, 5, 5, 1, 87522)\n",
      "(1, 1, 1, 15, 87522)\n",
      "(5, 5, 5, 31, 87522)\n",
      "(1, 1, 1, 30, 87522)\n",
      "(87522,)\n",
      "(5, 5, 5, 31, 87522)\n",
      "(1, 1, 1, 30, 87522)\n",
      "(87522,)\n",
      "(5, 5, 5, 31, 87521)\n",
      "(1, 1, 1, 30, 87521)\n",
      "(87521,)\n",
      "(5, 5, 5, 31, 87521)\n",
      "(1, 1, 1, 30, 87521)\n",
      "(87521,)\n",
      "(5, 5, 5, 31, 87519)\n",
      "(1, 1, 1, 30, 87519)\n",
      "87519.0\n",
      "43760.0\n",
      "float64\n",
      "float64\n",
      "(43760,)\n",
      "(87519,)\n",
      "[ True False  True ...  True  True False]\n",
      "(5, 5, 5, 31, 87519)\n",
      "(1, 1, 1, 30, 87519)\n",
      "87519.0\n",
      "43760.0\n",
      "float64\n",
      "float64\n",
      "(43760,)\n",
      "(87519,)\n",
      "[ True False  True ...  True  True False]\n",
      "(5, 5, 5, 31, 43759)\n",
      "(1, 1, 1, 30, 43759)\n",
      "(5, 5, 5, 31, 43759)\n",
      "(1, 1, 1, 30, 43759)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dirs)):\n",
    "#i = 0\n",
    "\n",
    "    data_path = \"/Users/kurtschilling/Data/harmonization/patches/s%s_A2B_5Patches.mat\" % (dirs[i])\n",
    "    print(data_path)\n",
    "    mat_contents = sio.loadmat(data_path)\n",
    "    #print(mat_contents)\n",
    "    \n",
    "    X1 = mat_contents['input1200_row1']; X2 = mat_contents['input1200_row2']; X3 = mat_contents['input1200_row3']\n",
    "    X4 = mat_contents['input1200_row4']; X5 = mat_contents['input1200_row5']\n",
    "\n",
    "    Z1 = mat_contents['input3000_row1']; Z2 = mat_contents['input3000_row2']; Z3 = mat_contents['input3000_row3']\n",
    "    Z4 = mat_contents['input3000_row4']; Z5 = mat_contents['input3000_row5']\n",
    "\n",
    "    Y1 = mat_contents['output1200']; Y2 = mat_contents['output3000'];\n",
    "    labels = mat_contents['labelsinput']\n",
    "    dims=X1.shape\n",
    "    print(dims)\n",
    "    print(labels.shape)\n",
    "    print(Y1.shape)\n",
    "\n",
    "    # output is output1200 output3000\n",
    "\n",
    "    XX = np.empty((5,5,5,31,dims[4]))\n",
    "    YY = np.empty((1,1,1,30,dims[4]))\n",
    "\n",
    "    XX[:,:,:,0,:] = labels[:,:,:,0,:]\n",
    "    XX[0,:,:,1:16,:] = X1; XX[1,:,:,1:16,:] = X2; XX[2,:,:,1:16,:] = X3; XX[3,:,:,1:16,:] = X4; XX[4,:,:,1:16,:] = X5\n",
    "    XX[0,:,:,16:32,:] = Z1; XX[1,:,:,16:32,:] = Z2; XX[2,:,:,16:32,:] = Z3; XX[3,:,:,16:32,:] = Z4; XX[4,:,:,16:32,:] = Z5\n",
    "\n",
    "    #print(XX[1,1,1,:,10000])\n",
    "\n",
    "    YY[:,:,:,0:15,:]=Y1; YY[:,:,:,15:31]=Y2\n",
    "\n",
    "    #print(YY[:,:,:,:,10000])\n",
    "    print(XX.shape)\n",
    "    print(YY.shape)\n",
    "    \n",
    "    # remove NAN, INF\n",
    "    from numpy import asarray as ar\n",
    "    arr1 = np.squeeze(np.isnan(YY).any(axis=3))\n",
    "    arr2 = np.squeeze(np.isinf(YY).any(axis=3))\n",
    "    arr3 = ar(arr1) | ar(arr2)\n",
    "    print(arr3.shape)\n",
    "\n",
    "    XX = XX[:,:,:,:,~arr3]\n",
    "    YY = YY[:,:,:,:,~arr3]\n",
    "    print(XX.shape)\n",
    "    print(YY.shape)\n",
    "\n",
    "    # remove >10\n",
    "    arr6 = np.squeeze(np.greater(np.abs(YY),10).any(axis=3))\n",
    "    print(arr6.shape)\n",
    "    XX = XX[:,:,:,:,~arr6]\n",
    "    YY = YY[:,:,:,:,~arr6]\n",
    "    print(XX.shape)\n",
    "    print(YY.shape)\n",
    "\n",
    "    #########\n",
    "    remaining_samples = XX.shape\n",
    "    remaining_samples = np.rint(remaining_samples[4])\n",
    "    remaining_samples.astype(int)\n",
    "    print(remaining_samples)\n",
    "    elim_length = np.rint(remaining_samples/5)\n",
    "    elim_length.astype(int)\n",
    "    print(elim_length)\n",
    "    print(elim_length.dtype)\n",
    "    print(remaining_samples.dtype)\n",
    "    arr7 = np.random.choice(remaining_samples.astype(int), elim_length.astype(int), replace = False)\n",
    "    print(arr7.shape)\n",
    "    mask = np.ones(remaining_samples.astype(int),dtype=bool)\n",
    "    print(mask.shape)\n",
    "    mask[[arr7]]=False\n",
    "    print(mask)\n",
    "    XX = XX[:,:,:,:,mask]\n",
    "    YY = YY[:,:,:,:,mask]\n",
    "    #Xv = Xv[:,:,:,:,arr7]\n",
    "    #Xv = np.delete(X,arr7,axis=4)\n",
    "    #Yv = np.delete(Y,arr7,axis=4)\n",
    "    #Yv = Yv[:,:,:,:,arr7]\n",
    "    print(XX.shape)\n",
    "    print(YY.shape)\n",
    "    #######\n",
    "    \n",
    "    X = np.append(X, XX, axis=4)\n",
    "    Y = np.append(Y, YY, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 5, 31, 431720)\n",
      "(1, 1, 1, 30, 431720)\n",
      "(5, 5, 5, 31, 431720)\n",
      "(1, 1, 1, 30, 431720)\n"
     ]
    }
   ],
   "source": [
    "del XX, YY, X1, X2, X3, X4, X5, Z1, Z2, Z3, Z4, Z5\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class SHDataSet(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return np.amax(X.shape)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        vec_a = self.X[:,:,:,:,i]\n",
    "        vec_b = self.Y[:,:,:,:,i]\n",
    "        vec_a = np.transpose(vec_a, (3, 0, 1, 2))\n",
    "        vec_b = np.transpose(vec_b, (3, 0, 1, 2))\n",
    "        a = torch.Tensor(vec_a)\n",
    "        b = torch.Tensor(vec_b.squeeze())\n",
    "    \n",
    "        return a,b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431720\n",
      "431720\n"
     ]
    }
   ],
   "source": [
    "shset = SHDataSet(X,Y)\n",
    "print(len(shset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cn1): Conv3d(31, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (cn2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=16000, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=60, bias=True)\n",
      "  (fc4): Linear(in_features=60, out_features=200, bias=True)\n",
      "  (fc5): Linear(in_features=200, out_features=30, bias=True)\n",
      ")\n",
      "Net(\n",
      "  (cn1): Conv3d(31, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (cn2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=16000, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=60, bias=True)\n",
      "  (fc4): Linear(in_features=60, out_features=200, bias=True)\n",
      "  (fc5): Linear(in_features=200, out_features=30, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.fc1 = nn.Linear(3 * 3 * 3 * 15, 600)\n",
    "        self.cn1 = nn.Conv3d(31,128,kernel_size=(3,3,3),stride=1,padding=(1,1,1))\n",
    "        self.cn2 = nn.Conv3d(128,128,kernel_size=(3,3,3),stride=1,padding=(1,1,1))\n",
    "        ## self.mp = nn.MaxPool(2)\n",
    "        #print(self.cn1.shape)\n",
    "        #self.fc2 = nn.Linear(600,300)\n",
    "        self.bn = nn.BatchNorm3d(128)\n",
    "        self.fc2 = nn.Linear(128*5*5*5, 300)\n",
    "        self.fc3 = nn.Linear(300,60)\n",
    "        self.fc4 = nn.Linear(60,200)\n",
    "        self.fc5 = nn.Linear(200,30)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.cn1(x))\n",
    "        x = F.relu(self.cn2(x))\n",
    "        ## x = self.mp(x)\n",
    "        print(x.shape)\n",
    "        dimensions = x.shape\n",
    "        x = self.bn(x)\n",
    "        x = x.view(dimensions[0], -1)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "        \n",
    "net = Net()\n",
    "print(net)  \n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "\n",
    "def train(model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = Variable(data).float(), Variable(target).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        output = output.to(device)\n",
    "\n",
    "        loss = criterion(output,target)\n",
    "        total_loss += loss.item()\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx*len(data),len(shset.X),100.*batch_idx/len(shset.X),loss.data[0]))\n",
    "\n",
    "    avg_loss = total_loss / batch_idx\n",
    "    print('\\tTraining set: Average loss: {:.4f}'.format(avg_loss))\n",
    "   \n",
    "    return avg_loss\n",
    "\n",
    "def test(model, device, loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = Variable(data).float(), Variable(target).float()\n",
    "\n",
    "        output = model(data)\n",
    "        output = output.to(device)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / batch_idx\n",
    "    print('\\tTesting set: Average loss: {:.4f}'.format(avg_loss))\n",
    "\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431720\n",
      "431720\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(shset)\n",
    "print(dataset_size)\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(shset, batch_size=bs_size, sampler=train_sampler)\n",
    "validation_loader = DataLoader(shset, batch_size=bs_size, sampler=valid_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_loss_file = 'BLAHFCN_L5PATCH_A2B_train_loss_split.txt'\n",
    "f = open(train_loss_file, 'w')\n",
    "f.close()\n",
    "validate_loss_file = 'BLAHFCN_L5PATCH_A2B_validate_loss_split.txt'\n",
    "f = open(validate_loss_file, 'w')\n",
    "f.close()\n",
    "\n",
    "model_file = 'BLAHFCN_L5PATCH_A2B_saved_model_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: \n",
      "\n",
      "Epoch 1: \n",
      "torch.Size([1000, 128, 5, 5, 5])\n",
      "torch.Size([1000, 128, 5, 5, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/5 (0%)]\tLoss: 0.084039\n",
      "Train Epoch: 1 [0/5 (0%)]\tLoss: 0.084039\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "        print('\\nEpoch %d: ' % epoch)\n",
    "        loss = train(net, device, train_loader, optimizer)\n",
    "\n",
    "        with open(train_loss_file, \"a\") as file:\n",
    "            file.write(str(loss))\n",
    "            file.write('\\n')\n",
    "\n",
    "        loss = test(net, device, validation_loader)\n",
    "\n",
    "        with open(validate_loss_file, \"a\") as file:\n",
    "            file.write(str(loss))\n",
    "            file.write('\\n')\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            with open(model_file, 'wb') as f:\n",
    "                torch.save(net.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
