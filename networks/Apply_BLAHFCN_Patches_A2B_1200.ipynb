{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import scipy.io as sio\n",
    "\n",
    "model_file = 'BLAHFCN_PATCH_A2B_SH1200_saved_model_split'\n",
    "dirs = ['H','L','M','N','O']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class SHDataSet(Dataset):\n",
    "    def __init__(self,X):\n",
    "        \n",
    "        self.X = X\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return np.amax(X.shape)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        vec_a = self.X[:,:,:,:,i]\n",
    "        vec_a = np.transpose(vec_a, (3, 0, 1, 2))\n",
    "        a = torch.Tensor(vec_a)\n",
    "    \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cn1): Conv3d(15, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=3456, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=60, bias=True)\n",
      "  (fc4): Linear(in_features=60, out_features=200, bias=True)\n",
      "  (fc5): Linear(in_features=200, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.fc1 = nn.Linear(3 * 3 * 3 * 15, 600)\n",
    "        self.cn1 = nn.Conv3d(15,128,kernel_size=(3,3,3),stride=1,padding=(1,1,1))\n",
    "        #print(self.cn1.shape)\n",
    "        #self.fc2 = nn.Linear(600,300)\n",
    "        self.bn = nn.BatchNorm3d(128)\n",
    "        self.fc2 = nn.Linear(128*3*3*3, 300)\n",
    "        self.fc3 = nn.Linear(300,60)\n",
    "        self.fc4 = nn.Linear(60,200)\n",
    "        self.fc5 = nn.Linear(200,15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.cn1(x))\n",
    "        #print(x.shape)\n",
    "        dimensions = x.shape\n",
    "        x = self.bn(x)\n",
    "        x = x.view(dimensions[0], -1)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "        \n",
    "net = Net()\n",
    "print(net)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kurtschilling/Data/harmonization/H_A2B_Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/CDMRI_Challenge_2018/Testing_Data/H/prisma/st/norm_dwi_SHfitOrder4_EvenOdd2_SH3000.nii.gz\n",
      "BLAHFCN_PATCHES_sH_A2B_SH1200.nii.gz\n",
      "(3, 3, 3, 15, 552960)\n",
      "(96, 96, 60, 15)\n",
      "(96, 96, 60, 15)\n",
      "(552960, 15)\n",
      "552960\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "(96, 96, 60, 15)\n",
      "/Users/kurtschilling/Data/harmonization/L_A2B_Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/CDMRI_Challenge_2018/Testing_Data/L/prisma/st/norm_dwi_SHfitOrder4_EvenOdd2_SH3000.nii.gz\n",
      "BLAHFCN_PATCHES_sL_A2B_SH1200.nii.gz\n",
      "(3, 3, 3, 15, 552960)\n",
      "(96, 96, 60, 15)\n",
      "(96, 96, 60, 15)\n",
      "(552960, 15)\n",
      "552960\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "(96, 96, 60, 15)\n",
      "/Users/kurtschilling/Data/harmonization/M_A2B_Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/CDMRI_Challenge_2018/Testing_Data/M/prisma/st/norm_dwi_SHfitOrder4_EvenOdd2_SH3000.nii.gz\n",
      "BLAHFCN_PATCHES_sM_A2B_SH1200.nii.gz\n",
      "(3, 3, 3, 15, 552960)\n",
      "(96, 96, 60, 15)\n",
      "(96, 96, 60, 15)\n",
      "(552960, 15)\n",
      "552960\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "(96, 96, 60, 15)\n",
      "/Users/kurtschilling/Data/harmonization/N_A2B_Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/CDMRI_Challenge_2018/Testing_Data/N/prisma/st/norm_dwi_SHfitOrder4_EvenOdd2_SH3000.nii.gz\n",
      "BLAHFCN_PATCHES_sN_A2B_SH1200.nii.gz\n",
      "(3, 3, 3, 15, 552960)\n",
      "(96, 96, 60, 15)\n",
      "(96, 96, 60, 15)\n",
      "(552960, 15)\n",
      "552960\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "(96, 96, 60, 15)\n",
      "/Users/kurtschilling/Data/harmonization/O_A2B_Patches.mat\n",
      "/Users/kurtschilling/Data/harmonization/CDMRI_Challenge_2018/Testing_Data/O/prisma/st/norm_dwi_SHfitOrder4_EvenOdd2_SH3000.nii.gz\n",
      "BLAHFCN_PATCHES_sO_A2B_SH1200.nii.gz\n",
      "(3, 3, 3, 15, 552960)\n",
      "(96, 96, 60, 15)\n",
      "(96, 96, 60, 15)\n",
      "(552960, 15)\n",
      "552960\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "(96, 96, 60, 15)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dirs)):\n",
    "\n",
    "    apply_to_file = \"/Users/kurtschilling/Data/harmonization/%s_A2B_Patches.mat\" % (dirs[i])\n",
    "    nii_file = \"/Users/kurtschilling/Data/harmonization/CDMRI_Challenge_2018/Testing_Data/%s/prisma/st/norm_dwi_SHfitOrder4_EvenOdd2_SH3000.nii.gz\" % (dirs[i])\n",
    "    save_file = \"BLAHFCN_PATCHES_s%s_A2B_SH1200.nii.gz\" % (dirs[i])\n",
    "    print(apply_to_file)\n",
    "    print(nii_file)\n",
    "    print(save_file)\n",
    "\n",
    "    # load and reshape\n",
    "    mat_contents = sio.loadmat(apply_to_file)\n",
    "    X = mat_contents['input1200']\n",
    "    print(X.shape)\n",
    "    \n",
    "    nifti_path = os.path.normpath(nii_file)\n",
    "    img = nib.load(nifti_path)\n",
    "    data = img.get_fdata()\n",
    "    dims = data.shape\n",
    "    print(dims)\n",
    "    \n",
    "    Y = np.zeros((dims[0],dims[1],dims[2],dims[3]))\n",
    "    print(Y.shape)\n",
    "    Y = np.reshape(Y,(dims[0]*dims[1]*dims[2],dims[3]))\n",
    "    print(Y.shape)\n",
    "    \n",
    "    shset = SHDataSet(X)\n",
    "    print(len(shset))\n",
    "\n",
    "    from torch.utils.data import DataLoader\n",
    "    test_loader = DataLoader(shset, batch_size=1)\n",
    "    \n",
    "    batch_idx = 0\n",
    "    for batch_idx, (data) in enumerate(test_loader):\n",
    "    \n",
    "        data = Variable(data).float()\n",
    "    \n",
    "        net_out = net(data)\n",
    "        b = net_out.detach().numpy()\n",
    "        c = np.reshape(b,(1,15))\n",
    "        #print(c.shape)\n",
    "        #print(batch_idx)\n",
    "        Y[batch_idx,:]=c;\n",
    "    \n",
    "    \n",
    "        if batch_idx % 100000 == 0:\n",
    "            print(batch_idx)\n",
    "            #print(b)\n",
    "\n",
    "    Y = np.reshape(Y,(dims[0],dims[1],dims[2],dims[3]))\n",
    "    print(Y.shape)\n",
    "    \n",
    "    new_img = nib.Nifti1Image(Y,img.affine,img.header)\n",
    "    nib.save(new_img,save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
