{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat,savemat\n",
    "import nibabel as nib\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "\n",
    "bs_size = 1000\n",
    "\n",
    "# v2: seperate training and testing and save as text\n",
    "# v3: include all 10 datasets and concatenate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kurtschilling/Data/harmonization/sA_A2D_Patches.mat\n",
      "(3, 3, 3, 15, 0)\n",
      "(1, 1, 1, 15, 581251)\n",
      "float64\n",
      "float64\n",
      "(581251,)\n",
      "(3, 3, 3, 15, 578226)\n",
      "(1, 1, 1, 15, 578226)\n",
      "(578226,)\n",
      "(3, 3, 3, 15, 578186)\n",
      "(1, 1, 1, 15, 578186)\n",
      "/Users/kurtschilling/Data/harmonization/sB_A2D_Patches.mat\n",
      "(3, 3, 3, 15, 578186)\n",
      "(1, 1, 1, 15, 641686)\n",
      "float64\n",
      "float64\n",
      "(641686,)\n",
      "(3, 3, 3, 15, 638880)\n",
      "(1, 1, 1, 15, 638880)\n",
      "(638880,)\n",
      "(3, 3, 3, 15, 638832)\n",
      "(1, 1, 1, 15, 638832)\n",
      "/Users/kurtschilling/Data/harmonization/sC_A2D_Patches.mat\n",
      "(3, 3, 3, 15, 1217018)\n",
      "(1, 1, 1, 15, 608309)\n",
      "float64\n",
      "float64\n",
      "(608309,)\n",
      "(3, 3, 3, 15, 606893)\n",
      "(1, 1, 1, 15, 606893)\n",
      "(606893,)\n",
      "(3, 3, 3, 15, 606774)\n",
      "(1, 1, 1, 15, 606774)\n",
      "/Users/kurtschilling/Data/harmonization/sD_A2D_Patches.mat\n",
      "(3, 3, 3, 15, 1823792)\n",
      "(1, 1, 1, 15, 568870)\n",
      "float64\n",
      "float64\n",
      "(568870,)\n",
      "(3, 3, 3, 15, 566984)\n",
      "(1, 1, 1, 15, 566984)\n",
      "(566984,)\n",
      "(3, 3, 3, 15, 566947)\n",
      "(1, 1, 1, 15, 566947)\n",
      "/Users/kurtschilling/Data/harmonization/sE_A2D_Patches.mat\n",
      "(3, 3, 3, 15, 2390739)\n",
      "(1, 1, 1, 15, 580779)\n",
      "float64\n",
      "float64\n",
      "(580779,)\n",
      "(3, 3, 3, 15, 580459)\n",
      "(1, 1, 1, 15, 580459)\n",
      "(580459,)\n",
      "(3, 3, 3, 15, 580424)\n",
      "(1, 1, 1, 15, 580424)\n",
      "/Users/kurtschilling/Data/harmonization/sF_A2D_Patches.mat\n",
      "(3, 3, 3, 15, 2971163)\n",
      "(1, 1, 1, 15, 595421)\n",
      "float64\n",
      "float64\n",
      "(595421,)\n",
      "(3, 3, 3, 15, 591371)\n",
      "(1, 1, 1, 15, 591371)\n",
      "(591371,)\n",
      "(3, 3, 3, 15, 591317)\n",
      "(1, 1, 1, 15, 591317)\n",
      "/Users/kurtschilling/Data/harmonization/sG_A2D_Patches.mat\n",
      "(3, 3, 3, 15, 3562480)\n",
      "(1, 1, 1, 15, 671952)\n",
      "float64\n",
      "float64\n",
      "(671952,)\n",
      "(3, 3, 3, 15, 664945)\n",
      "(1, 1, 1, 15, 664945)\n",
      "(664945,)\n",
      "(3, 3, 3, 15, 664864)\n",
      "(1, 1, 1, 15, 664864)\n",
      "/Users/kurtschilling/Data/harmonization/sI_A2D_Patches.mat\n",
      "(3, 3, 3, 15, 4227344)\n",
      "(1, 1, 1, 15, 635096)\n",
      "float64\n",
      "float64\n",
      "(635096,)\n",
      "(3, 3, 3, 15, 630008)\n",
      "(1, 1, 1, 15, 630008)\n",
      "(630008,)\n",
      "(3, 3, 3, 15, 629946)\n",
      "(1, 1, 1, 15, 629946)\n",
      "/Users/kurtschilling/Data/harmonization/sJ_A2D_Patches.mat\n",
      "(3, 3, 3, 15, 4857290)\n",
      "(1, 1, 1, 15, 635222)\n",
      "float64\n",
      "float64\n",
      "(635222,)\n",
      "(3, 3, 3, 15, 634547)\n",
      "(1, 1, 1, 15, 634547)\n",
      "(634547,)\n",
      "(3, 3, 3, 15, 634526)\n",
      "(1, 1, 1, 15, 634526)\n"
     ]
    }
   ],
   "source": [
    "dirs = ['A','B','C','D','E','F','G','I','J','K']\n",
    "\n",
    "X = np.empty((3,3,3,15,0))\n",
    "Y = np.empty((1,1,1,15,0))\n",
    "\n",
    "#numbers = [6]\n",
    "for i in range(len(dirs)):\n",
    "#for i in numbers:\n",
    "    data_path = \"/Users/kurtschilling/Data/harmonization/s%s_A2D_Patches.mat\" % (dirs[i])\n",
    "    print(data_path)\n",
    "    \n",
    "    mat_contents = sio.loadmat(data_path)\n",
    "    # mat_contents\n",
    "    Xv = mat_contents['input1200']\n",
    "    Xv = np.float64(Xv)\n",
    "    print(X.shape)\n",
    "    Yv = mat_contents['output1200']\n",
    "    Yv = np.float64(Yv)\n",
    "    \n",
    "    print(Yv.shape)\n",
    "    print(Xv.dtype)\n",
    "    print(Yv.dtype)\n",
    "    \n",
    "    # remove NAN, INF\n",
    "    from numpy import asarray as ar\n",
    "\n",
    "    arr1 = np.squeeze(np.isnan(Yv).any(axis=3))\n",
    "    arr2 = np.squeeze(np.isinf(Yv).any(axis=3))\n",
    "    arr3 = ar(arr1) | ar(arr2)\n",
    "    print(arr3.shape)\n",
    "\n",
    "    #X = np.delete(X,arr3,4)\n",
    "    #Y = np.delete(Y,arr3,4)\n",
    "    Xv = Xv[:,:,:,:,~arr3]\n",
    "    Yv = Yv[:,:,:,:,~arr3]\n",
    "    print(Xv.shape)\n",
    "    print(Yv.shape)\n",
    "\n",
    "    # remove >10\n",
    "    arr6 = np.squeeze(np.greater(np.abs(Yv),10).any(axis=3))\n",
    "    print(arr6.shape)\n",
    "    #X = np.delete(X,arr6,4)\n",
    "    #Y = np.delete(Y,arr6,4)\n",
    "    Xv = Xv[:,:,:,:,~arr6]\n",
    "    Yv = Yv[:,:,:,:,~arr6]\n",
    "    print(Xv.shape)\n",
    "    print(Yv.shape)\n",
    "\n",
    "    X = np.append(X, Xv, axis=4)\n",
    "    Y = np.append(Y, Yv, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(np.amax(X.shape))\n",
    "print(np.amax(Xv.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class SHDataSet(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return np.amax(X.shape)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        #vec_a = np.reshape(self.X[i,:],(15, 1, 1))\n",
    "        #vec_b = np.reshape(self.Y[i,:],(15, 1, 1))\n",
    "        vec_a = self.X[:,:,:,:,i]\n",
    "        vec_b = self.Y[:,:,:,:,i]\n",
    "        #vec_a = np.reshape(self.X[i,:],(1, 15, 1))\n",
    "        #vec_b = np.reshape(self.Y[i,:],(1, 15, 1))\n",
    "        vec_a = np.transpose(vec_a, (3, 0, 1, 2))\n",
    "        vec_b = np.transpose(vec_b, (3, 0, 1, 2))\n",
    "        #a = self.to_tensor(vec_a)\n",
    "        #b = self.to_tensor(vec_b)\n",
    "        a = torch.Tensor(vec_a)\n",
    "        b = torch.Tensor(vec_b.squeeze())\n",
    "    \n",
    "        return a,b\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shset = SHDataSet(X,Y)\n",
    "print(len(shset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X.dtype)\n",
    "print(Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.fc1 = nn.Linear(3 * 3 * 3 * 15, 600)\n",
    "        self.cn1 = nn.Conv3d(15,128,kernel_size=(3,3,3),stride=1,padding=(1,1,1))\n",
    "        #print(self.cn1.shape)\n",
    "        #self.fc2 = nn.Linear(600,300)\n",
    "        self.bn = nn.BatchNorm3d(128)\n",
    "        self.fc2 = nn.Linear(128*3*3*3, 300)\n",
    "        self.fc3 = nn.Linear(300,60)\n",
    "        self.fc4 = nn.Linear(60,200)\n",
    "        self.fc5 = nn.Linear(200,15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.cn1(x))\n",
    "        #print(x.shape)\n",
    "        dimensions = x.shape\n",
    "        x = self.bn(x)\n",
    "        x = x.view(dimensions[0], -1)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "        \n",
    "net = Net()\n",
    "print(net)  \n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "\n",
    "def train(model, device, loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = Variable(data).float(), Variable(target).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        output = output.to(device)\n",
    "\n",
    "        loss = criterion(output,target)\n",
    "        total_loss += loss.item()\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx*len(data),len(shset.X),100.*batch_idx/len(shset.X),loss.data[0]))\n",
    "\n",
    "    avg_loss = total_loss / batch_idx\n",
    "    print('\\tTraining set: Average loss: {:.4f}'.format(avg_loss))\n",
    "   \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = Variable(data).float(), Variable(target).float()\n",
    "\n",
    "        output = model(data)\n",
    "        output = output.to(device)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / batch_idx\n",
    "    print('\\tTesting set: Average loss: {:.4f}'.format(avg_loss))\n",
    "\n",
    "    return avg_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(shset)\n",
    "print(dataset_size)\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(shset, batch_size=bs_size, sampler=train_sampler)\n",
    "validation_loader = DataLoader(shset, batch_size=bs_size, sampler=valid_sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_loss_file = 'BLAHFCN_PATCH_A2D_SH1200_train_loss_split.txt'\n",
    "f = open(train_loss_file, 'w')\n",
    "f.close()\n",
    "validate_loss_file = 'BLAHFCN_PATCH_A2D_SH1200_validate_loss_split.txt'\n",
    "f = open(validate_loss_file, 'w')\n",
    "f.close()\n",
    "\n",
    "model_file = 'BLAHFCN_PATCH_A2D_SH1200_saved_model_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 51):\n",
    "        print('\\nEpoch %d: ' % epoch)\n",
    "        loss = train(net, device, train_loader, optimizer)\n",
    "\n",
    "        with open(train_loss_file, \"a\") as file:\n",
    "            file.write(str(loss))\n",
    "            file.write('\\n')\n",
    "\n",
    "        loss = test(net, device, validation_loader)\n",
    "\n",
    "        with open(validate_loss_file, \"a\") as file:\n",
    "            file.write(str(loss))\n",
    "            file.write('\\n')\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            with open(model_file, 'wb') as f:\n",
    "                torch.save(net.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
